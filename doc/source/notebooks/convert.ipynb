{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60fd7d0e-a46e-4db0-8bbe-00256058ee71",
   "metadata": {},
   "source": [
    "# Convert and Characterize MRIO satellite accounts and results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850708b0-66c3-4ca8-a50b-f7396ec4c1a7",
   "metadata": {},
   "source": [
    "Here we discuss the possibilities for converting MRIO satellite accounts (Extensions)\n",
    "and results.\n",
    "The term *convert* is used very broadly here, it includes the following tasks:\n",
    "\n",
    "- renaming the index names of results/extensions\n",
    "- adjusting the numerical values of the data,\n",
    "  e.g. for unit conversion or characterisation\n",
    "- finding and extracting data based on indicies across a table or an mrio(-extension).\n",
    "  This can be system based on name and potentially constrained by sector/region\n",
    "  or any other specification.\n",
    "- Aggregation/Summation of satellite accounts\n",
    "- Characterization of stressors to impact categories\n",
    "\n",
    "We will cover each of these points in the examples below.\n",
    "We will start with applying the conversion to a single table\n",
    "and then cover the conversion of a full MRIO extension.\n",
    "\n",
    "For the connected topic of *Aggregation of MRIOs*\n",
    "see the [Aggregation](./aggregation_examples.ipynb) page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde3cf89-6c36-47dd-b9d5-48433f4473b5",
   "metadata": {},
   "source": [
    "## Basic setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bc1d78",
   "metadata": {},
   "source": [
    "All conversion relies on a *mapping table* that maps (bridges)\n",
    "the index/columns of the source data to the indices of the target data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849bc1ef",
   "metadata": {},
   "source": [
    "This tables requires headers (columns) corresponding to the\n",
    "index.names and columns.names of the source data (constraining data)\n",
    "as well as bridge data  which specify the new target index.\n",
    "The later are indicated by \"NewIndex__OldIndex\" - **the important part are\n",
    "the two underscore in the column name**. Another (optional)\n",
    "column named \"factor\" specifies\n",
    "the multiplication factor for the conversion.\n",
    "TODO:CHECK Finally, additional columns can be used to indicate units and other information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b5425f",
   "metadata": {},
   "source": [
    "Constraining data columns can either specify columns or index.\n",
    "However, any constraining data to be bridged/mapped to a new name need to be\n",
    "in the index of the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3ec2d8",
   "metadata": {},
   "source": [
    "The first example below shows the simplest case of renaming a single table.\n",
    "This will make the concept of the mapping table clear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2125d8",
   "metadata": {},
   "source": [
    "## Renaming the index of a single table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e97063",
   "metadata": {},
   "source": [
    "Assume we have a small MRIO result table with the following structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7e3af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import pymrio\n",
    "\n",
    "ghg_result = pd.DataFrame(\n",
    "    columns=[\"Region1\", \"Region2\", \"Region3\"],\n",
    "    index=pd.MultiIndex.from_tuples(\n",
    "        [\n",
    "            (\"Carbon Dioxide\", \"Air\"),\n",
    "            (\"Methane\", \"air\"),\n",
    "        ]\n",
    "    ),\n",
    "    data=[[5, 6, 7], [0.5, 0.6, 0.7]],\n",
    ")\n",
    "ghg_result.index.names = [\"stressor\", \"compartment\"]\n",
    "ghg_result.columns.names = [\"region\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bf2941",
   "metadata": {},
   "source": [
    "Our first task here is to rename to the chemical names of the stressors\n",
    "and fix the compartment spelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72ae844",
   "metadata": {},
   "outputs": [],
   "source": [
    "ghg_map = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"stressor\",\n",
    "        \"compartment\",\n",
    "        \"chem_stressor__stressor\",\n",
    "        \"compartment__compartment\",\n",
    "        \"factor\",\n",
    "    ],\n",
    "    data=[\n",
    "        [\"Carbon Dioxide\", \"[A|a]ir\", \"CO2\", \"Air\", 1.0],\n",
    "        [\"Methane\", \"[A|a]ir\", \"CH4\", \"Air\", 1.0],\n",
    "    ],\n",
    ")\n",
    "ghg_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73cd886",
   "metadata": {},
   "outputs": [],
   "source": [
    "ghg_new = pymrio.convert(ghg_result, ghg_map)\n",
    "ghg_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17f0c5d",
   "metadata": {},
   "source": [
    "Explanation: The column headers indicates that the stressor index level\n",
    "should be renamed from \"stressor\" to \"chem_stressor\" and the compartment index level\n",
    "should stay the same (NewName__OldName). The factor column is not used in this case.\n",
    "All renaming columns consider regular expressions,\n",
    "so that the spelling of the compartment can be fixed in one go."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9d7152",
   "metadata": {},
   "source": [
    "For simple rename (and aggregation cases, see below) we can omit the factor column.\n",
    "Thus we obtain the same result with the following mapping table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48688b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "ghg_map_wo_factor = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"stressor\",\n",
    "        \"compartment\",\n",
    "        \"chem_stressor__stressor\",\n",
    "        \"compartment__compartment\",\n",
    "    ],\n",
    "    data=[\n",
    "        [\"Carbon Dioxide\", \"[A|a]ir\", \"CO2\", \"Air\"],\n",
    "        [\"Methane\", \"[A|a]ir\", \"CH4\", \"Air\"],\n",
    "    ],\n",
    ")\n",
    "ghg_map_wo_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826f558a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "ghg_new_wo_factor = pymrio.convert(ghg_result, ghg_map_wo_factor)\n",
    "ghg_new_wo_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f1c043",
   "metadata": {},
   "source": [
    "## Unit conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77c7c19",
   "metadata": {},
   "source": [
    "With the factor column it is easy to apply unit conversion to any result table.\n",
    "So, to start with the same table as above, we can apply a simple unit conversion.\n",
    "Assuming the data is in tonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fe084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ghg_result_ton = pd.DataFrame(\n",
    "    columns=[\"Region1\", \"Region2\", \"Region3\"],\n",
    "    index=pd.MultiIndex.from_tuples(\n",
    "        [\n",
    "            (\"Carbon Dioxide\", \"Air\"),\n",
    "            (\"Methane\", \"air\"),\n",
    "        ]\n",
    "    ),\n",
    "    data=[[5, 6, 7], [0.5, 0.6, 0.7]],\n",
    ")\n",
    "ghg_result_ton.index.names = [\"stressor\", \"compartment\"]\n",
    "ghg_result_ton.columns.names = [\"region\"]\n",
    "ghg_result_ton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad41ad6",
   "metadata": {},
   "source": [
    "We can get the data in kg by\n",
    "\n",
    "\n",
    "ghg_map_to_kg = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"stressor\",\n",
    "        \"compartment\",\n",
    "        \"chem_stressor__stressor\",\n",
    "        \"compartment__compartment\",\n",
    "        \"factor\",\n",
    "    ],\n",
    "    data=[\n",
    "        [\"Carbon Dioxide\", \"[A|a]ir\", \"CO2\", \"Air\", 1000],\n",
    "        [\"Methane\", \"[A|a]ir\", \"CH4\", \"Air\", 1000],\n",
    "    ],\n",
    ")\n",
    "ghg_map_to_kg\n",
    "\n",
    "ghg_new_kg = pymrio.convert(ghg_result_ton, ghg_map_to_kg)\n",
    "ghg_new_kg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7738e2d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "In case of unit conversion of pymrio satellite accounts,\n",
    "we can also check the unit before and set the unit after conversion:\n",
    "TODO: unit conversion extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7024fc74",
   "metadata": {},
   "source": [
    "## Characterization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f00d51",
   "metadata": {},
   "source": [
    "The main power of the convert function is to aggregate and characterize satellite accounts.\n",
    "If needed, region and sector specific characterizations can be applied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643b8d26",
   "metadata": {},
   "source": [
    "### Global characterization factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44aabe37",
   "metadata": {},
   "source": [
    "An simple example is a conversion/aggregation based on GWP100 characterization factors.\n",
    "Here, we continue with the unit converted and cleanup dataframe from above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677f3872",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "ghg_new_kg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a102de0a",
   "metadata": {},
   "source": [
    "We define a general purpose characterization map for GHG emissions\n",
    "(based on\n",
    "[AR6 GWP100 and GWP20 factors](https://www.ipcc.ch/report/ar6/wg1/downloads/report/IPCC_AR6_WGI_Chapter07.pdf)\n",
    ",with some simplifications):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289eae3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GWP_characterization = pd.DataFrame(\n",
    "    columns=[\"chem_stressor\", \"GWP__chem_stressor\", \"factor\"],\n",
    "    data=[\n",
    "        [\"CO2\", \"GWP100\", 1],\n",
    "        [\"CH4\", \"GWP100\", 29],\n",
    "        [\"NHx\", \"GWP100\", 273],\n",
    "        [\"CO2\", \"GWP20\", 1],\n",
    "        [\"CH4\", \"GWP20\", 80],\n",
    "        [\"NHx\", \"GWP20\", 273],\n",
    "        [\"CO2\", \"GWP500\", 1],\n",
    "        [\"CH4\", \"GWP500\", 8],\n",
    "        [\"NHx\", \"GWP500\", 130],\n",
    "    ],\n",
    ")\n",
    "GWP_characterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04df3552",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "GWP_result = pymrio.convert(ghg_new_kg, GWP_characterization)\n",
    "GWP_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0706fdb9",
   "metadata": {},
   "source": [
    "As we can see, GWP_characterization can include factors for stressors not actually\n",
    "present in the data.\n",
    "These are silently ignored in the conversion process.\n",
    "We also did not specify the compartment and assumed the same factors apply\n",
    "independent of the compartment (we could pass through the compartment to\n",
    "the new result table via passing drop_not_bridge=False to the convert function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab77360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "GWP_result_with_comp = pymrio.convert(\n",
    "    ghg_new_kg, GWP_characterization, drop_not_bridged=False\n",
    ")\n",
    "GWP_result_with_comp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8347eaf5",
   "metadata": {},
   "source": [
    "All stressors mapped to the same \"impact\" are first converted via the\n",
    "value given in the factor column\n",
    "and then summed up (the aggregation function can be changed\n",
    "via the `agg_func` parameter)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bb8bec",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### Regional specific characterization factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe2789b",
   "metadata": {},
   "source": [
    "A more complex example is the application of regional specific characterization\n",
    "factors (the same principle applies to sector specific factors.).\n",
    "For that, we assume some land use results for different regions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00156b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "land_use_result = pd.DataFrame(\n",
    "    columns=[\"Region1\", \"Region2\", \"Region3\"],\n",
    "    index=[\n",
    "        \"Wheat\",\n",
    "        \"Maize\",\n",
    "        \"Rice\",\n",
    "        \"Pasture\",\n",
    "        \"Forest extensive\",\n",
    "        \"Forest intensive\",\n",
    "    ],\n",
    "    data=[\n",
    "        [3, 10, 1],\n",
    "        [5, 20, 3],\n",
    "        [0, 12, 34],\n",
    "        [12, 34, 9],\n",
    "        [32, 27, 11],\n",
    "        [43, 17, 24],\n",
    "    ],\n",
    ")\n",
    "land_use_result.index.names = [\"stressor\"]\n",
    "land_use_result.columns.names = [\"region\"]\n",
    "land_use_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e356ee1",
   "metadata": {},
   "source": [
    "Now we setup a pseudo characterization table for converting the land use data into\n",
    "biodiversity impacts. We assume, that the characterization factors vary based on\n",
    "land use type and region. However, the \"region\" information is a pure\n",
    "constraining column (specifying the region for which the factor applies) without\n",
    "any bridge column mapping it to a new name. Thus, the \"region\" can either be in the index\n",
    "or in the columns of the source data - in the given case it is in the columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1b48ff",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "landuse_characterization = pd.DataFrame(\n",
    "    columns=[\"stressor\", \"BioDiv__stressor\", \"region\", \"factor\"],\n",
    "    data=[\n",
    "        [\"Wheat|Maize\", \"BioImpact\", \"Region1\", 3],\n",
    "        [\"Wheat\", \"BioImpact\", \"Region[2,3]\", 4],\n",
    "        [\"Maize\", \"BioImpact\", \"Region[2,3]\", 7],\n",
    "        [\"Rice\", \"BioImpact\", \"Region1\", 12],\n",
    "        [\"Rice\", \"BioImpact\", \"Region2\", 12],\n",
    "        [\"Rice\", \"BioImpact\", \"Region3\", 12],\n",
    "        [\"Pasture\", \"BioImpact\", \"Region[1,2,3]\", 12],\n",
    "        [\"Forest.*\", \"BioImpact\", \"Region1\", 2],\n",
    "        [\"Forest.*\", \"BioImpact\", \"Region2\", 3],\n",
    "        [\"Forest ext.*\", \"BioImpact\", \"Region3\", 1],\n",
    "        [\"Forest int.*\", \"BioImpact\", \"Region3\", 3],\n",
    "    ],\n",
    ")\n",
    "landuse_characterization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee910ad",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "The table shows several possibilities to specify factors which apply to several\n",
    "regions/stressors.\n",
    "All of them are based on the [regular expression](https://docs.python.org/3/howto/regex.html):\n",
    "\n",
    "- In the first data line we use the \"or\" operator \"|\" to specify that the\n",
    "same factor applies to Wheat and Maize.\n",
    "- On the next line we use the grouping capabilities of regular expressions\n",
    "to indicate the same factor for Region 2 and 3.\n",
    "- At the last four lines .* matches any number of characters. This\n",
    "allows to specify the same factor for both forest types or to abbreviate\n",
    "the naming of the stressor (last 2 lines).\n",
    "\n",
    "The use of regular expression is optional, one can also use one line per factor.\n",
    "In the example above, we indicate the factor for Rice in 3 subsequent entries.\n",
    "This would be equivalent to ```[\"Rice\", \"BioImpact\", \"Region[1,2,3]\", 12]```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0e5a7c",
   "metadata": {},
   "source": [
    "With that setup we can now characterize the land use data in land_use_result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2e3a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "biodiv_result = pymrio.convert(land_use_result, landuse_characterization)\n",
    "biodiv_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c48b45",
   "metadata": {},
   "source": [
    "Note, that in this example the region is not in the index\n",
    "but in the columns.\n",
    "The convert function can handle both cases.\n",
    "The only difference is that constraints which are\n",
    "in the columns will never be aggregated but keep the column resolution at the\n",
    "output. Thus the result is equivalent to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d435a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "land_use_result_stacked = land_use_result.stack(level=\"region\")\n",
    "biodiv_result_stacked = pymrio.convert(\n",
    "    land_use_result_stacked, landuse_characterization, drop_not_bridged_index=False\n",
    ")\n",
    "biodiv_result_stacked.unstack(level=\"region\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e09b7d4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "In this case we have to specify to not drop the not bridged \"region\" index.\n",
    "We then unstack the result again, and have to select the first element ([0]),\n",
    "since there where not other columns left after stacking them before the\n",
    "characterization.\n",
    "\n",
    "CONT: start working on convert for extensions/mrio method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b48a82",
   "metadata": {},
   "source": [
    "Irrespectively of the table or the mrio system, the convert function always follows the same pattern.\n",
    "It requires a bridge table, which contains the mapping of the indicies of the source data to the indicies of the target data.\n",
    "This bridge table has to follow a specific format, depending on the table to be converted."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
